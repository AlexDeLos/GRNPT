{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "from graph_construction import construct_graph\n",
    "from tcn_autoencoder import train_and_extract_features\n",
    "from data_splitting import create_train_val_tf, generate_train_val_kfold\n",
    "from transformer_model import train_model, test_model\n",
    "from data_splitting import split_edges, split_tfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"mESC\"\n",
    "adata = sc.read(\"./dataset/\" +file_name + \".h5ad\")\n",
    "\n",
    "filtered_refnet = adata.uns[\"grn\"]\n",
    "fea_df = pd.DataFrame(adata.uns[\"gpt_emb\"])\n",
    "fea_df[\"Gene\"] = adata.var_names\n",
    "X_norm = adata.X.T\n",
    "tfs = np.unique(filtered_refnet[\"Gene1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/Documents/GitHub/GRNPT/graph_construction.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  edge_index = torch.tensor([le.transform(filtered_refnet['Gene1']),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[500, 1536], edge_index=[2, 2347])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_orig, tfs_index, le = construct_graph(filtered_refnet, adata.var_names,fea_df, tfs)\n",
    "data_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/Documents/GitHub/GRNPT/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200]\n",
      "Epoch [2/200]\n",
      "Epoch [3/200]\n",
      "Epoch [4/200]\n",
      "Epoch [5/200]\n",
      "Epoch [6/200]\n",
      "Epoch [7/200]\n",
      "Epoch [8/200]\n",
      "Epoch [9/200]\n",
      "Epoch [10/200]\n",
      "Epoch [11/200]\n",
      "Epoch [12/200]\n",
      "Epoch [13/200]\n",
      "Epoch [14/200]\n",
      "Epoch [15/200]\n",
      "Epoch [16/200]\n",
      "Epoch [17/200]\n",
      "Epoch [18/200]\n",
      "Epoch [19/200]\n",
      "Epoch [20/200]\n",
      "Epoch [21/200]\n",
      "Epoch [22/200]\n",
      "Epoch [23/200]\n",
      "Epoch [24/200]\n",
      "Epoch [25/200]\n",
      "Epoch [26/200]\n",
      "Epoch [27/200]\n",
      "Epoch [28/200]\n",
      "Epoch [29/200]\n",
      "Epoch [30/200]\n",
      "Epoch [31/200]\n",
      "Epoch [32/200]\n",
      "Epoch [33/200]\n",
      "Epoch [34/200]\n",
      "Epoch [35/200]\n",
      "Epoch [36/200]\n",
      "Epoch [37/200]\n",
      "Epoch [38/200]\n",
      "Epoch [39/200]\n",
      "Epoch [40/200]\n",
      "Epoch [41/200]\n",
      "Epoch [42/200]\n",
      "Epoch [43/200]\n",
      "Epoch [44/200]\n",
      "Epoch [45/200]\n",
      "Epoch [46/200]\n",
      "Epoch [47/200]\n",
      "Epoch [48/200]\n",
      "Epoch [49/200]\n",
      "Epoch [50/200]\n",
      "Epoch [51/200]\n",
      "Epoch [52/200]\n",
      "Epoch [53/200]\n",
      "Epoch [54/200]\n",
      "Epoch [55/200]\n",
      "Epoch [56/200]\n",
      "Epoch [57/200]\n",
      "Epoch [58/200]\n",
      "Epoch [59/200]\n",
      "Epoch [60/200]\n",
      "Epoch [61/200]\n",
      "Epoch [62/200]\n",
      "Epoch [63/200]\n",
      "Epoch [64/200]\n",
      "Epoch [65/200]\n",
      "Epoch [66/200]\n",
      "Epoch [67/200]\n",
      "Epoch [68/200]\n",
      "Epoch [69/200]\n",
      "Epoch [70/200]\n",
      "Epoch [71/200]\n",
      "Epoch [72/200]\n",
      "Epoch [73/200]\n",
      "Epoch [74/200]\n",
      "Epoch [75/200]\n",
      "Epoch [76/200]\n",
      "Epoch [77/200]\n",
      "Epoch [78/200]\n",
      "Epoch [79/200]\n",
      "Epoch [80/200]\n",
      "Epoch [81/200]\n",
      "Epoch [82/200]\n",
      "Epoch [83/200]\n",
      "Epoch [84/200]\n",
      "Epoch [85/200]\n",
      "Epoch [86/200]\n",
      "Epoch [87/200]\n",
      "Epoch [88/200]\n",
      "Epoch [89/200]\n",
      "Epoch [90/200]\n",
      "Epoch [91/200]\n",
      "Epoch [92/200]\n",
      "Epoch [93/200]\n",
      "Epoch [94/200]\n",
      "Epoch [95/200]\n",
      "Epoch [96/200]\n",
      "Epoch [97/200]\n",
      "Epoch [98/200]\n",
      "Epoch [99/200]\n",
      "Epoch [100/200]\n",
      "Epoch [101/200]\n",
      "Epoch [102/200]\n",
      "Epoch [103/200]\n",
      "Epoch [104/200]\n",
      "Epoch [105/200]\n",
      "Epoch [106/200]\n",
      "Epoch [107/200]\n",
      "Epoch [108/200]\n",
      "Epoch [109/200]\n",
      "Epoch [110/200]\n",
      "Epoch [111/200]\n",
      "Epoch [112/200]\n",
      "Epoch [113/200]\n",
      "Epoch [114/200]\n",
      "Epoch [115/200]\n",
      "Epoch [116/200]\n",
      "Epoch [117/200]\n",
      "Epoch [118/200]\n",
      "Epoch [119/200]\n",
      "Epoch [120/200]\n",
      "Epoch [121/200]\n",
      "Epoch [122/200]\n",
      "Epoch [123/200]\n",
      "Epoch [124/200]\n",
      "Epoch [125/200]\n",
      "Epoch [126/200]\n",
      "Epoch [127/200]\n",
      "Epoch [128/200]\n",
      "Epoch [129/200]\n",
      "Epoch [130/200]\n",
      "Epoch [131/200]\n",
      "Epoch [132/200]\n",
      "Epoch [133/200]\n",
      "Epoch [134/200]\n",
      "Epoch [135/200]\n",
      "Epoch [136/200]\n",
      "Epoch [137/200]\n",
      "Epoch [138/200]\n",
      "Epoch [139/200]\n",
      "Epoch [140/200]\n",
      "Epoch [141/200]\n",
      "Epoch [142/200]\n",
      "Epoch [143/200]\n",
      "Epoch [144/200]\n",
      "Epoch [145/200]\n",
      "Epoch [146/200]\n",
      "Epoch [147/200]\n",
      "Epoch [148/200]\n",
      "Epoch [149/200]\n",
      "Epoch [150/200]\n",
      "Epoch [151/200]\n",
      "Epoch [152/200]\n",
      "Epoch [153/200]\n",
      "Epoch [154/200]\n",
      "Epoch [155/200]\n",
      "Epoch [156/200]\n",
      "Epoch [157/200]\n",
      "Epoch [158/200]\n",
      "Epoch [159/200]\n",
      "Epoch [160/200]\n",
      "Epoch [161/200]\n",
      "Epoch [162/200]\n",
      "Epoch [163/200]\n",
      "Epoch [164/200]\n",
      "Epoch [165/200]\n",
      "Epoch [166/200]\n",
      "Epoch [167/200]\n",
      "Epoch [168/200]\n",
      "Epoch [169/200]\n",
      "Epoch [170/200]\n",
      "Epoch [171/200]\n",
      "Epoch [172/200]\n",
      "Epoch [173/200]\n",
      "Epoch [174/200]\n",
      "Epoch [175/200]\n",
      "Epoch [176/200]\n",
      "Epoch [177/200]\n",
      "Epoch [178/200]\n",
      "Epoch [179/200]\n",
      "Epoch [180/200]\n",
      "Epoch [181/200]\n",
      "Epoch [182/200]\n",
      "Epoch [183/200]\n",
      "Epoch [184/200]\n",
      "Epoch [185/200]\n",
      "Epoch [186/200]\n",
      "Epoch [187/200]\n",
      "Epoch [188/200]\n",
      "Epoch [189/200]\n",
      "Epoch [190/200]\n",
      "Epoch [191/200]\n",
      "Epoch [192/200]\n",
      "Epoch [193/200]\n",
      "Epoch [194/200]\n",
      "Epoch [195/200]\n",
      "Epoch [196/200]\n",
      "Epoch [197/200]\n",
      "Epoch [198/200]\n",
      "Epoch [199/200]\n",
      "Epoch [200/200]\n",
      "Training complete.\n",
      "Features extracted. Shape: torch.Size([500, 36, 421])\n",
      "Reduced features shape: torch.Size([500, 36])\n",
      "torch.Size([500, 36])\n"
     ]
    }
   ],
   "source": [
    "# train the auto encoder and extract the features from it\n",
    "tcauto_model, features = train_and_extract_features(X_norm,learning_rate=0.001, weight_decay=1e-4)\n",
    "print(features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[500, 1536], edge_index=[2, 2347], x_additional=[500, 36])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_features_df = pd.DataFrame(features.cpu().numpy())\n",
    "reduced_features_df[\"Gene\"] = adata.var_names\n",
    "reduced_features_df\n",
    "\n",
    "# create features of nodes\n",
    "node_features_1 = fea_df.set_index('Gene').reindex(le.classes_).fillna(0).values\n",
    "node_features_2 = reduced_features_df.set_index('Gene').reindex(le.classes_).fillna(0).values\n",
    "\n",
    "\n",
    "x = torch.tensor(node_features_1, dtype=torch.float)\n",
    "x_additional = torch.tensor(node_features_2, dtype=torch.float)\n",
    "# build graph object\n",
    "data = Data(x=x, x_additional=x_additional, edge_index=data_orig.edge_index)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_sets_kfold = generate_train_val_kfold(data,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Data(x=[500, 1536], edge_label_index=[2, 235], edge_label=[235], x_additional=[500, 36]),\n",
       "  Data(x=[500, 1536], edge_label_index=[2, 4224], edge_label=[4224], x_additional=[500, 36])),\n",
       " (Data(x=[500, 1536], edge_label_index=[2, 235], edge_label=[235], x_additional=[500, 36]),\n",
       "  Data(x=[500, 1536], edge_label_index=[2, 4224], edge_label=[4224], x_additional=[500, 36])),\n",
       " (Data(x=[500, 1536], edge_label_index=[2, 235], edge_label=[235], x_additional=[500, 36]),\n",
       "  Data(x=[500, 1536], edge_label_index=[2, 4224], edge_label=[4224], x_additional=[500, 36])),\n",
       " (Data(x=[500, 1536], edge_label_index=[2, 235], edge_label=[235], x_additional=[500, 36]),\n",
       "  Data(x=[500, 1536], edge_label_index=[2, 4224], edge_label=[4224], x_additional=[500, 36])),\n",
       " (Data(x=[500, 1536], edge_label_index=[2, 235], edge_label=[235], x_additional=[500, 36]),\n",
       "  Data(x=[500, 1536], edge_label_index=[2, 4224], edge_label=[4224], x_additional=[500, 36])),\n",
       " (Data(x=[500, 1536], edge_label_index=[2, 235], edge_label=[235], x_additional=[500, 36]),\n",
       "  Data(x=[500, 1536], edge_label_index=[2, 4224], edge_label=[4224], x_additional=[500, 36])),\n",
       " (Data(x=[500, 1536], edge_label_index=[2, 235], edge_label=[235], x_additional=[500, 36]),\n",
       "  Data(x=[500, 1536], edge_label_index=[2, 4224], edge_label=[4224], x_additional=[500, 36])),\n",
       " (Data(x=[500, 1536], edge_label_index=[2, 234], edge_label=[234], x_additional=[500, 36]),\n",
       "  Data(x=[500, 1536], edge_label_index=[2, 4226], edge_label=[4226], x_additional=[500, 36])),\n",
       " (Data(x=[500, 1536], edge_label_index=[2, 234], edge_label=[234], x_additional=[500, 36]),\n",
       "  Data(x=[500, 1536], edge_label_index=[2, 4226], edge_label=[4226], x_additional=[500, 36])),\n",
       " (Data(x=[500, 1536], edge_label_index=[2, 234], edge_label=[234], x_additional=[500, 36]),\n",
       "  Data(x=[500, 1536], edge_label_index=[2, 4226], edge_label=[4226], x_additional=[500, 36]))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_sets_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "--------------\n",
      "Fold 2:\n",
      "--------------\n",
      "Fold 3:\n",
      "--------------\n",
      "Fold 4:\n",
      "--------------\n",
      "Fold 5:\n",
      "--------------\n",
      "Fold 6:\n",
      "--------------\n",
      "Fold 7:\n",
      "--------------\n",
      "Fold 8:\n",
      "--------------\n",
      "Fold 9:\n",
      "--------------\n",
      "Fold 10:\n",
      "--------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(np.float64(0.9422497781695589), np.float64(0.9380913099871461)),\n",
       " (np.float64(0.9322687555139428), np.float64(0.9415692054840911)),\n",
       " (np.float64(0.9271067770398809), np.float64(0.9329777195639909)),\n",
       " (np.float64(0.9399754745164731), np.float64(0.9493861832493462)),\n",
       " (np.float64(0.9253774891940774), np.float64(0.9255588587001925)),\n",
       " (np.float64(0.9481379066076442), np.float64(0.9619429359055307)),\n",
       " (np.float64(0.9363832455797686), np.float64(0.942159381593986)),\n",
       " (np.float64(0.9033548486118099), np.float64(0.9110622520448427)),\n",
       " (np.float64(0.9277950032414456), np.float64(0.9441822186097422)),\n",
       " (np.float64(0.9277621255293877), np.float64(0.9294655557767938))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_val_sets = train_val_sets_kfold\n",
    "\n",
    "results = []\n",
    "\n",
    "for fold, (train_data, val_data) in enumerate(train_val_sets):\n",
    "    print(f'Fold {fold + 1}:')\n",
    "    \n",
    "    # training\n",
    "    model = train_model(\n",
    "        train_data, \n",
    "        \n",
    "        hidden_channels=64, \n",
    "        num_heads=16, \n",
    "        dropout=0.5, \n",
    "        lr=0.000005, \n",
    "        weight_decay=1e-3, \n",
    "        num_epochs=200, \n",
    "        print_interval=10\n",
    "    )\n",
    "    \n",
    "    results.append({\n",
    "        'fold': fold + 1,\n",
    "       \n",
    "        'model': model\n",
    "    })\n",
    "    \n",
    "    print('--------------')\n",
    "\n",
    "\n",
    "\n",
    "model_list = [r['model'] for r in results]\n",
    "test_auc = [test_model(i, val_data) for i in model_list]\n",
    "test_auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
